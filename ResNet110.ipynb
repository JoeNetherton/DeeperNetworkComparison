{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet110.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DVc0whGyzR",
        "colab_type": "code",
        "outputId": "8462d7c4-8405-4206-ee1b-e808bf0d4e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import mnist\n",
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 18\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "#'cifar', 'fashion mnist', 'mnist'\n",
        "DATASET_USED = 'mnist'\n",
        "\n",
        "\n",
        "def resize(mnist):\n",
        "     #function resizes the dimensions of inputted dataset\n",
        "     data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            data.append(resized_img)\n",
        "     return data\n",
        "\n",
        "\n",
        "if DATASET_USED == \"cifar\":\n",
        "  # Load the CIFAR10 data.\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "if DATASET_USED == \"fashion mnist\":\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "  x_train = np.array(resize(x_train))\n",
        "  x_test = np.array(resize(x_test))\n",
        "\n",
        "  x_train = x_train.reshape(x_train.shape[0], 32, 32, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 32, 32, 1)\n",
        "\n",
        "if DATASET_USED == \"mnist\":\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  x_train = np.array(resize(x_train))\n",
        "  x_test = np.array(resize(x_test))\n",
        "\n",
        "  x_train = x_train.reshape(x_train.shape[0], 32, 32, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 32, 32, 1)\n",
        "\n",
        "\n",
        "\n",
        "#x_train = np.array(resize(x_train))\n",
        "#x_test = np.array(resize(x_test))\n",
        "\n",
        "\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 90:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 60:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 40:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "'''\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(learning_rate=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "'''\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    datagen = ImageDataGenerator(\n",
        "        '''\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0\n",
        "        '''\n",
        "        )\n",
        "    \n",
        "\n",
        "    history = model.fit(x_train, y_train, \n",
        "                        validation_data=(x_test, y_test), batch_size=batch_size,\n",
        "                        epochs=epochs, verbose=1)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        '''\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0\n",
        "        '''\n",
        "        )\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    '''\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "    '''\n",
        "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=epochs, verbose=1)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "\n",
        "####\n",
        "#with augmentation\n",
        "###"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 32, 32, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (60000,)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   160         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 16)   2320        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 16)   0           activation_11[0][0]              \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 16)   0           activation_13[0][0]              \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 32, 32, 16)   0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 16)   2320        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 16)   0           activation_19[0][0]              \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 16)   2320        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 16)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 16)   2320        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 16)   0           activation_21[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 16)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2320        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 16)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 16)   2320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 16)   0           activation_23[0][0]              \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 16)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 16)   2320        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 16)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 16)   2320        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 16)   64          conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 32, 32, 16)   0           activation_25[0][0]              \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 16)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 16)   2320        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 16)   64          conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 16)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 16)   2320        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 16)   64          conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 32, 32, 16)   0           activation_27[0][0]              \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 16)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 16)   2320        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 16)   64          conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 16)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 16)   2320        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 16)   64          conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 32, 32, 16)   0           activation_29[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 16)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 16)   2320        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 16)   64          conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 16)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 16)   2320        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 32, 32, 16)   0           activation_31[0][0]              \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 16)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 16)   2320        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 32, 32, 16)   64          conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 16)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 16)   2320        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 32, 32, 16)   64          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 32, 32, 16)   0           activation_33[0][0]              \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 16)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 16)   2320        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 32, 32, 16)   64          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 32, 16)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 16)   2320        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 32, 32, 16)   0           activation_35[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 32, 32, 16)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 32)   4640        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 32)   9248        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 32)   544         activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 32)   0           conv2d_41[0][0]                  \n",
            "                                                                 batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 32)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 32)   9248        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 32)   128         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 32)   9248        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 16, 16, 32)   0           activation_39[0][0]              \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 32)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 32)   9248        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 32)   128         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 32)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 32)   9248        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 32)   128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 16, 16, 32)   0           activation_41[0][0]              \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 32)   0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 32)   9248        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 32)   128         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 32)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 32)   9248        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 16, 16, 32)   0           activation_43[0][0]              \n",
            "                                                                 batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 32)   0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 32)   9248        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 32)   128         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 32)   9248        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 16, 16, 32)   0           activation_45[0][0]              \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 32)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 32)   9248        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 32)   9248        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 32)   128         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 16, 16, 32)   0           activation_47[0][0]              \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 32)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 32)   9248        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 32)   128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 16, 16, 32)   0           activation_49[0][0]              \n",
            "                                                                 batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 32)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 32)   9248        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 32)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 32)   9248        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 16, 16, 32)   0           activation_51[0][0]              \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 32)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 32)   128         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 32)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 32)   9248        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 32)   128         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 16, 16, 32)   0           activation_53[0][0]              \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 32)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 32)   9248        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 32)   128         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 32)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 32)   128         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 16, 16, 32)   0           activation_55[0][0]              \n",
            "                                                                 batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 32)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 32)   9248        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 32)   128         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 32)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 32)   9248        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 32)   128         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 16, 16, 32)   0           activation_57[0][0]              \n",
            "                                                                 batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 32)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 32)   9248        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 32)   128         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 32)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 32)   9248        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 32)   128         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 16, 16, 32)   0           activation_59[0][0]              \n",
            "                                                                 batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 32)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 32)   9248        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 32)   128         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 32)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 32)   9248        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 32)   128         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 16, 16, 32)   0           activation_61[0][0]              \n",
            "                                                                 batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 32)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 32)   9248        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 32)   128         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 32)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 32)   9248        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 32)   128         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 16, 16, 32)   0           activation_63[0][0]              \n",
            "                                                                 batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 32)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 16, 16, 32)   9248        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 32)   128         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 32)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 16, 16, 32)   9248        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 16, 16, 32)   128         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 16, 16, 32)   0           activation_65[0][0]              \n",
            "                                                                 batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 32)   0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 16, 16, 32)   9248        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 32)   128         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 32)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 16, 16, 32)   9248        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 16, 16, 32)   128         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 16, 16, 32)   0           activation_67[0][0]              \n",
            "                                                                 batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 16, 16, 32)   0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 16, 16, 32)   9248        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 16, 16, 32)   128         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 16, 16, 32)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 16, 16, 32)   9248        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 16, 16, 32)   128         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 16, 16, 32)   0           activation_69[0][0]              \n",
            "                                                                 batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 16, 16, 32)   0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 16, 16, 32)   9248        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 16, 16, 32)   128         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 16, 16, 32)   0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 16, 16, 32)   9248        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 16, 16, 32)   128         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 16, 16, 32)   0           activation_71[0][0]              \n",
            "                                                                 batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 16, 16, 32)   0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 64)     18496       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 64)     256         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 64)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 64)     36928       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 64)     2112        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 64)     256         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 8, 8, 64)     0           conv2d_78[0][0]                  \n",
            "                                                                 batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 64)     0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 64)     36928       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 64)     256         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 64)     0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 64)     36928       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 64)     256         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 8, 8, 64)     0           activation_75[0][0]              \n",
            "                                                                 batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 64)     0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 64)     36928       activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 64)     256         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 64)     0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 64)     36928       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 64)     256         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 8, 8, 64)     0           activation_77[0][0]              \n",
            "                                                                 batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 64)     0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 64)     36928       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 64)     256         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 64)     0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 64)     36928       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 64)     256         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 8, 8, 64)     0           activation_79[0][0]              \n",
            "                                                                 batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 64)     0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 64)     36928       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 64)     256         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 64)     0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 64)     36928       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 64)     256         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 8, 8, 64)     0           activation_81[0][0]              \n",
            "                                                                 batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 64)     0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 64)     36928       activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 64)     256         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 64)     0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 64)     36928       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 64)     256         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 8, 8, 64)     0           activation_83[0][0]              \n",
            "                                                                 batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 64)     0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 64)     36928       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 64)     256         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 64)     0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 64)     36928       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 64)     256         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 8, 8, 64)     0           activation_85[0][0]              \n",
            "                                                                 batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 64)     0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 64)     36928       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 64)     256         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 64)     0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 64)     36928       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 64)     256         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 8, 8, 64)     0           activation_87[0][0]              \n",
            "                                                                 batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 64)     0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 64)     36928       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 64)     256         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 64)     0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 64)     36928       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 64)     256         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 8, 8, 64)     0           activation_89[0][0]              \n",
            "                                                                 batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 64)     0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 64)     36928       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 64)     256         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 64)     0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 64)     36928       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 64)     256         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 8, 8, 64)     0           activation_91[0][0]              \n",
            "                                                                 batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 64)     0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 64)     36928       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 64)     256         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 64)     0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 64)     36928       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 64)     256         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 8, 8, 64)     0           activation_93[0][0]              \n",
            "                                                                 batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 64)     0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 8, 8, 64)     36928       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 64)     256         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 64)     0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 8, 8, 64)     36928       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 64)     256         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 8, 8, 64)     0           activation_95[0][0]              \n",
            "                                                                 batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 64)     0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 8, 8, 64)     36928       activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 64)     256         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 64)     0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 8, 8, 64)     36928       activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 8, 8, 64)     256         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 8, 8, 64)     0           activation_97[0][0]              \n",
            "                                                                 batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 8, 8, 64)     0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 8, 8, 64)     36928       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 8, 8, 64)     256         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 8, 8, 64)     0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 8, 8, 64)     36928       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 8, 8, 64)     256         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 8, 8, 64)     0           activation_99[0][0]              \n",
            "                                                                 batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 8, 8, 64)     0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 8, 8, 64)     36928       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 8, 8, 64)     256         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 8, 8, 64)     0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 8, 8, 64)     36928       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 8, 8, 64)     256         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 8, 8, 64)     0           activation_101[0][0]             \n",
            "                                                                 batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 8, 8, 64)     0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 8, 8, 64)     36928       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 8, 8, 64)     256         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 8, 8, 64)     0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 8, 8, 64)     36928       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 8, 8, 64)     256         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 8, 8, 64)     0           activation_103[0][0]             \n",
            "                                                                 batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 8, 8, 64)     0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 8, 8, 64)     36928       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 8, 8, 64)     256         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 8, 8, 64)     0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 8, 8, 64)     36928       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 8, 8, 64)     256         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 8, 8, 64)     0           activation_105[0][0]             \n",
            "                                                                 batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 8, 8, 64)     0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 8, 8, 64)     36928       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 8, 8, 64)     256         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 8, 8, 64)     0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 8, 8, 64)     36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 8, 8, 64)     256         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 8, 8, 64)     0           activation_107[0][0]             \n",
            "                                                                 batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 8, 8, 64)     0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,742,474\n",
            "Trainable params: 1,734,378\n",
            "Non-trainable params: 8,096\n",
            "__________________________________________________________________________________________________\n",
            "ResNet110v1\n",
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2327\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'mean_27' has no attr named '_XlaCompile'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2331\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2333\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Operation 'mean_27' has no attr named '_XlaCompile'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fcab229bea33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    511\u001b[0m     history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n\u001b[1;32m    512\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                     epochs=epochs, verbose=1)\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;31m# Score trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3023\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3025\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[0;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    303\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 669\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    670\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    334\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 669\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    670\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     factor = _safe_shape_div(\n\u001b[0;32m--> 265\u001b[0;31m         math_ops.reduce_prod(input_shape), math_ops.reduce_prod(output_shape))\n\u001b[0m\u001b[1;32m    266\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_prod\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2194\u001b[0m       gen_math_ops.prod(\n\u001b[1;32m   2195\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m           name=name))\n\u001b[0m\u001b[1;32m   2197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   6640\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m   6641\u001b[0m         \u001b[0;34m\"Prod\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6642\u001b[0;31m                 name=name)\n\u001b[0m\u001b[1;32m   6643\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6644\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1789\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m     \u001b[0;31m# List of _UserDevSpecs holding code location of device context manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(limit)\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0m_source_mapper_stacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       _source_filter_stacks[thread_key])\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mStackSummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStackSummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkiAWxHcHqb6",
        "colab_type": "code",
        "outputId": "584a7cee-56ef-41ba-dc06-6c2c809eec11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': [0.9987252900123597, 0.9544616937637329, 0.8931531511306763, 0.9012140954971314, 0.8760899574279785, 0.8703186395645142, 0.8665031925201416, 0.8929020189285278, 0.8675377536773682, 0.8568567879676818, 0.851228983592987, 0.852292995262146, 0.8570684274673462, 0.8478291445732117, 0.8421625851631165, 0.8461073711395264, 0.8405426939010621, 0.8434072714805603, 0.8386526178359985, 0.8350691346168518, 0.8328751255989074, 0.8341403199195861, 0.8315350539207459, 0.8337638088226318, 0.831305826473236, 0.8278683955192566, 0.8278680681228637, 0.8248988110542297, 0.8258542108535767, 0.8256907791137695, 0.8208622695922851, 0.8192723422050476, 0.8173008283615112, 0.8179870483398437, 0.8161074103355408, 0.8138830219268799, 0.8143625144958496, 0.8128583065032959, 0.811675299835205, 0.8091732389450074, 0.8092453639984131, 0.8067427043914794, 0.8074050199508667, 0.8024796245574951, 0.8035501741409302, 0.8006931011199951, 0.8001767696380615, 0.7975286487579346, 0.7967625434875488, 0.7956457221031189, 0.7943214067459107, 0.7941635976791381, 0.7923824704170227, 0.7902814303398132, 0.7884748208999633, 0.7868655148506165, 0.7867809163093566, 0.7835042516708374, 0.7829721426010132, 0.7842877109527588, 0.7816276271820068, 0.780718969631195, 0.7781451108932496, 0.7792150701522828, 0.776941773033142, 0.7737996333122253, 0.7722470301628113, 0.7714232629776001, 0.7714691724777222, 0.7687776270866394, 0.7672423581123352, 0.7667844505310059, 0.7650494703292847, 0.7640206884384155, 0.7625257173538208, 0.761172809791565, 0.7596345302581787, 0.758007640171051, 0.7562681380271912, 0.7556659775733948, 0.753958356666565, 0.7531188619613648, 0.7526286406517029, 0.7517757588386536, 0.758427705860138, 0.7482701976776123, 0.7468835770606994, 0.7452625717163086, 0.7440570718765259, 0.7428792761802674, 0.7416124057769775, 0.7411386451721191, 0.7405233119010926, 0.7375052880287171, 0.7378843934059143, 0.7366566040992737, 0.7340301958084107, 0.7336415794372558, 0.7310541904449462, 0.7301557777404785], 'val_accuracy': [0.9537000060081482, 0.9628999829292297, 0.9776999950408936, 0.9761999845504761, 0.9815999865531921, 0.9830999970436096, 0.9851999878883362, 0.9757000207901001, 0.9830999970436096, 0.9864000082015991, 0.9876000285148621, 0.9861000180244446, 0.9835000038146973, 0.9868999719619751, 0.9886999726295471, 0.9866999983787537, 0.9876999855041504, 0.9876000285148621, 0.9876999855041504, 0.9889000058174133, 0.9884999990463257, 0.9872999787330627, 0.9882000088691711, 0.9882000088691711, 0.9878000020980835, 0.9883999824523926, 0.988099992275238, 0.988099992275238, 0.9886000156402588, 0.9887999892234802, 0.9891999959945679, 0.9889000058174133, 0.989300012588501, 0.9886000156402588, 0.9891999959945679, 0.9894000291824341, 0.9884999990463257, 0.9884999990463257, 0.9883999824523926, 0.9887999892234802, 0.9884999990463257, 0.9890999794006348, 0.9887999892234802, 0.9891999959945679, 0.9878000020980835, 0.9887999892234802, 0.9886000156402588, 0.9890999794006348, 0.9889000058174133, 0.9886000156402588, 0.9889000058174133, 0.9886999726295471, 0.9886999726295471, 0.9890999794006348, 0.9890000224113464, 0.9890000224113464, 0.9883999824523926, 0.9891999959945679, 0.9890999794006348, 0.9883999824523926, 0.9886999726295471, 0.9879999756813049, 0.9890999794006348, 0.9886000156402588, 0.9890000224113464, 0.9891999959945679, 0.9891999959945679, 0.9886999726295471, 0.9883000254631042, 0.9894000291824341, 0.989300012588501, 0.9889000058174133, 0.9887999892234802, 0.9889000058174133, 0.9886000156402588, 0.9890000224113464, 0.9890000224113464, 0.9894000291824341, 0.9890000224113464, 0.9889000058174133, 0.9894000291824341, 0.9890999794006348, 0.9883000254631042, 0.9883000254631042, 0.9873999953269958, 0.9890000224113464, 0.9891999959945679, 0.989300012588501, 0.9890000224113464, 0.9887999892234802, 0.9889000058174133, 0.9886000156402588, 0.9886999726295471, 0.9887999892234802, 0.9884999990463257, 0.9883000254631042, 0.9890000224113464, 0.9887999892234802, 0.9891999959945679, 0.9887999892234802], 'loss': [1.4971210851669312, 0.9530728007316589, 0.9076435967127482, 0.8842999984105429, 0.8714949647267659, 0.8613655411720276, 0.8524914935429891, 0.8451942177136739, 0.839662979888916, 0.8339536759376526, 0.8296582454681396, 0.8252015409469604, 0.8206137343088786, 0.8177851761500041, 0.8143869957923889, 0.81141596326828, 0.8092694305737813, 0.8065379532496134, 0.8044705953280131, 0.8023717888514201, 0.8002374939282735, 0.7987771047592163, 0.7967093367576599, 0.7955191136360168, 0.793338221168518, 0.791760698668162, 0.789936971728007, 0.7885256109873454, 0.7868376398722331, 0.7852804354985555, 0.7835628339131673, 0.7820374771753947, 0.7804881229082743, 0.7789506707509358, 0.7774165515899658, 0.7759721254348755, 0.7743741536458333, 0.7729715690294902, 0.771422491868337, 0.7699121404647827, 0.7684470742225648, 0.7670301187197367, 0.7655282056172689, 0.764110927549998, 0.7626267814318339, 0.7611700721104939, 0.7597237109184265, 0.7582559931437175, 0.7567556578318279, 0.75534221423467, 0.7539232866923015, 0.7524716437657674, 0.751066592725118, 0.7496567075093588, 0.748245574760437, 0.7468008366584777, 0.7453695805549622, 0.74399565893809, 0.7426244513511657, 0.7412142145792643, 0.7398629246075948, 0.7384213674545288, 0.7369759899139404, 0.7356133088111877, 0.7342151456832886, 0.7328333396911622, 0.7315007483800252, 0.7301211810111999, 0.7287516608874003, 0.7273100796381633, 0.7259761610031128, 0.7246314607302348, 0.7232847080230713, 0.7218869260787963, 0.7205139213879903, 0.7191587110837301, 0.7177962324778239, 0.7164273005803427, 0.7151157696723938, 0.7137934975624084, 0.7124086069107056, 0.7110891122817993, 0.7097585586547852, 0.7084192498207093, 0.7071000894228617, 0.7057449198404948, 0.7044628848711649, 0.7031066378275553, 0.7017858101844787, 0.700457258383433, 0.6991594810167948, 0.6978545278549194, 0.6965056565602621, 0.695223716990153, 0.6939244439125061, 0.6926038916269938, 0.6912904156684876, 0.6899990599632263, 0.6887077813784281, 0.6874042776107788], 'accuracy': [0.81233335, 0.9641333, 0.97566664, 0.98193336, 0.98583335, 0.9877667, 0.9899, 0.9916833, 0.9928667, 0.99438334, 0.99545, 0.9965, 0.99768335, 0.9979333, 0.99881667, 0.9989333, 0.99901664, 0.9995833, 0.99953336, 0.99975, 0.99988335, 0.99978334, 0.9999667, 0.9998, 0.99993336, 0.99986666, 0.99993336, 0.99988335, 0.99988335, 0.9999833, 0.9999833, 0.9999667, 0.9999833, 1.0, 1.0, 0.9999833, 1.0, 0.9999833, 0.9999833, 0.9999833, 1.0, 0.9999833, 1.0, 1.0, 0.9999833, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999833, 1.0, 1.0, 0.9999833, 0.9999833, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999833, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGhHaAp8YNRF",
        "colab_type": "code",
        "outputId": "db0ba4a5-0670-4324-fe04-e99c7d8b24af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss') # \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss') # b is for \"solid blue line\"\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZhU5Zn38e8NtCCbIDSoNNiQgIiyN25ERWMmoI4riTJEZYwSiIlbEjVxEo2JM8mEzDgkUYMbmhDQMRleF4jGBcGYRBYRAVFRaWkEgUY2AWW53z+eU1A0XdXddJ+u7jq/z3XVVXWWOnWfOlB3P8t5HnN3REQkuZrkOgAREcktJQIRkYRTIhARSTglAhGRhFMiEBFJOCUCEZGEUyKQOmVmM83sirreN5fMbIWZnRXDcd3MPh+9vtfMflidfQ/ic0ab2bMHG2eW4w4zs7K6Pq7Uv2a5DkByz8y2pi22BD4FdkfL33D3KdU9lruPiGPffOfu4+riOGZWDLwPFLj7rujYU4BqX0NJHiUCwd1bp16b2QrgKnd/ruJ+ZtYs9eMiIvlDVUOSUarob2Y3m9ka4CEza29mT5nZOjP7OHpdlPaeWWZ2VfR6jJm9bGYTon3fN7MRB7lvdzObbWZbzOw5M/uNmf0+Q9zVifEnZvbX6HjPmlnHtO2XmVmpmZWb2a1Zvp8TzWyNmTVNW3ehmS2KXp9gZn8zs41mttrMfm1mh2Q41mQz+2na8vei93xoZldW2PccM3vNzDab2Uozuz1t8+zoeaOZbTWzk1Pfbdr7TzGzuWa2KXo+pbrfTTZmdmz0/o1mtsTMzkvbdraZLY2OucrMvhut7xhdn41mtsHM5piZfpfqmb5wqcoRwOHA0cBYwr+Zh6LlbsB24NdZ3n8i8BbQEfhP4AEzs4PY9w/Aq0AH4HbgsiyfWZ0Y/wX4V6ATcAiQ+mHqA9wTHf+o6POKqIS7/wP4BDizwnH/EL3eDdwQnc/JwBeBb2aJmyiG4VE8XwJ6AhXbJz4BLgfaAecA483sgmjbadFzO3dv7e5/q3Dsw4GngYnRuf0X8LSZdahwDgd8N1XEXAA8CTwbve/bwBQzOyba5QFCNWMb4HjghWj9d4AyoBDoDPwA0Lg39UyJQKqyB7jN3T919+3uXu7uf3T3be6+BbgTOD3L+0vd/T533w08DBxJ+A9f7X3NrBswBPiRu3/m7i8DT2T6wGrG+JC7v+3u24HHgAHR+pHAU+4+290/BX4YfQeZTAVGAZhZG+DsaB3uPt/d/+7uu9x9BfDbSuKozFej+Ba7+yeExJd+frPc/Q133+Pui6LPq85xISSOd9z9d1FcU4FlwD+n7ZPpu8nmJKA18LPoGr0APEX03QA7gT5m1tbdP3b3BWnrjwSOdved7j7HNQBavVMikKqsc/cdqQUza2lmv42qTjYTqiLapVePVLAm9cLdt0UvW9dw36OADWnrAFZmCriaMa5Je70tLaaj0o8d/RCXZ/oswl//F5lZc+AiYIG7l0Zx9IqqPdZEcfw7oXRQlf1iAEornN+JZvZiVPW1CRhXzeOmjl1aYV0p0CVtOdN3U2XM7p6eNNOPezEhSZaa2UtmdnK0/hfAcuBZM3vPzG6p3mlIXVIikKpU/OvsO8AxwInu3pZ9VRGZqnvqwmrgcDNrmbaua5b9axPj6vRjR5/ZIdPO7r6U8IM3gv2rhSBUMS0DekZx/OBgYiBUb6X7A6FE1NXdDwPuTTtuVX9Nf0ioMkvXDVhVjbiqOm7XCvX7e4/r7nPd/XxCtdF0QkkDd9/i7t9x9x7AecCNZvbFWsYiNaREIDXVhlDnvjGqb74t7g+M/sKeB9xuZodEf03+c5a31CbGx4FzzewLUcPuHVT9/+QPwHWEhPO/FeLYDGw1s97A+GrG8Bgwxsz6RImoYvxtCCWkHWZ2AiEBpawjVGX1yHDsGUAvM/sXM2tmZpcAfQjVOLXxD0Lp4SYzKzCzYYRrNC26ZqPN7DB330n4TvYAmNm5Zvb5qC1oE6FdJVtVnMRAiUBq6i7gUGA98Hfgz/X0uaMJDa7lwE+BRwn3O1TmoGN09yXANYQf99XAx4TGzGxSdfQvuPv6tPXfJfxIbwHui2KuTgwzo3N4gVBt8kKFXb4J3GFmW4AfEf11Hb13G6FN5K9RT5yTKhy7HDiXUGoqB24Czq0Qd425+2eEH/4RhO/9buByd18W7XIZsCKqIhtHuJ4QGsOfA7YCfwPudvcXaxOL1JypXUYaIzN7FFjm7rGXSETynUoE0iiY2RAz+5yZNYm6V55PqGsWkVrSncXSWBwB/InQcFsGjHf313Ibkkh+UNWQiEjCqWpIRCThGl3VUMeOHb24uDjXYYiINCrz589f7+6FlW1rdImguLiYefPm5ToMEZFGxcwq3lG+l6qGREQSTolARCThlAhERBKu0bURiEj927lzJ2VlZezYsaPqnSWnWrRoQVFREQUFBdV+T2yJwMweJIxpstbdj69k+zDg/xHmVwX4k7vfEVc8InLwysrKaNOmDcXFxWSeV0hyzd0pLy+nrKyM7t27V/t9cVYNTQaGV7HPHHcfED1iSwJTpkBxMTRpEp6naBpvkRrZsWMHHTp0UBJo4MyMDh061LjkFluJwN1nm1lxXMevrilTYOxY2BZNaVJaGpYBRo/O/D4R2Z+SQONwMNcp143FJ5vZ62Y208yOi+MDbr11XxJI2bYtrBcRkdwmggWEeUr7A78iy0iSZjbWzOaZ2bx169bV6EM++KBm60Wk4SkvL2fAgAEMGDCAI444gi5duuxd/uyzz7K+d968eVx77bVVfsYpp5xSJ7HOmjWLc889t06OVV9ylgjcfbO7b41ezwAKzKzSeVfdfZK7l7h7SWFhpXdIZ9St4iR/VawXkdqr63a5Dh06sHDhQhYuXMi4ceO44YYb9i4fcsgh7Nq1K+N7S0pKmDhxYpWf8corr9QuyEYsZ4nAzI6Ipqcjmm6vCdknCT8od94JLVvuv65ly7BeROpeql2utBTc97XL1XUnjTFjxjBu3DhOPPFEbrrpJl599VVOPvlkBg4cyCmnnMJbb70F7P8X+u23386VV17JsGHD6NGjx34JonXr1nv3HzZsGCNHjqR3796MHj2a1CjNM2bMoHfv3gwePJhrr722yr/8N2zYwAUXXEC/fv046aSTWLRoEQAvvfTS3hLNwIED2bJlC6tXr+a0005jwIABHH/88cyZM6duv7As4uw+OhUYBnQ0szLCvKsFAO5+LzASGG9muwjzy17qMYyJnWoQvvXWUB3UrVtIAmooFolHtna5uv5/V1ZWxiuvvELTpk3ZvHkzc+bMoVmzZjz33HP84Ac/4I9//OMB71m2bBkvvvgiW7Zs4ZhjjmH8+PEH9Ll/7bXXWLJkCUcddRRDhw7lr3/9KyUlJXzjG99g9uzZdO/enVGjRlUZ32233cbAgQOZPn06L7zwApdffjkLFy5kwoQJ/OY3v2Ho0KFs3bqVFi1aMGnSJL785S9z6623snv3brZV/BJjFGevoazfkrv/Gvh1XJ+fbvRo/fCL1Jf6bJf7yle+QtOmTQHYtGkTV1xxBe+88w5mxs6dOyt9zznnnEPz5s1p3rw5nTp14qOPPqKoqGi/fU444YS96wYMGMCKFSto3bo1PXr02Ns/f9SoUUyaNClrfC+//PLeZHTmmWdSXl7O5s2bGTp0KDfeeCOjR4/moosuoqioiCFDhnDllVeyc+dOLrjgAgYMGFCr76Ymct1rSETyTH22y7Vq1Wrv6x/+8IecccYZLF68mCeffDJjX/rmzZvvfd20adNK2xeqs09t3HLLLdx///1s376doUOHsmzZMk477TRmz55Nly5dGDNmDI888kidfmY2SgQiUqdy1S63adMmunTpAsDkyZPr/PjHHHMM7733HitWrADg0UcfrfI9p556KlOixpFZs2bRsWNH2rZty7vvvkvfvn25+eabGTJkCMuWLaO0tJTOnTtz9dVXc9VVV7FgwYI6P4dMlAhEpE6NHg2TJsHRR4NZeJ40Kf7q2Ztuuonvf//7DBw4sM7/ggc49NBDufvuuxk+fDiDBw+mTZs2HHbYYVnfc/vttzN//nz69evHLbfcwsMPPwzAXXfdxfHHH0+/fv0oKChgxIgRzJo1i/79+zNw4EAeffRRrrvuujo/h0wa3ZzFJSUlrolpROrXm2++ybHHHpvrMHJu69attG7dGnfnmmuuoWfPntxwww25DusAlV0vM5vv7iWV7a8SgYhINd13330MGDCA4447jk2bNvGNb3wj1yHVCQ1DLSJSTTfccEODLAHUlkoEIiIJp0QgIpJwSgQiIgmnRCAiknBKBCLS4J1xxhk888wz+6276667GD9+fMb3DBs2jFRX87PPPpuNGzcesM/tt9/OhAkTsn729OnTWbp06d7lH/3oRzz33HM1Cb9SDWm4aiUCEWnwRo0axbRp0/ZbN23atGoN/AZh1NB27dod1GdXTAR33HEHZ5111kEdq6FSIhCRBm/kyJE8/fTTeyehWbFiBR9++CGnnnoq48ePp6SkhOOOO47bbrut0vcXFxezfv16AO6880569erFF77whb1DVUO4R2DIkCH079+fiy++mG3btvHKK6/wxBNP8L3vfY8BAwbw7rvvMmbMGB5//HEAnn/+eQYOHEjfvn258sor+fTTT/d+3m233cagQYPo27cvy5Yty3p+uR6uWvcRiEiNXH89LFxYt8ccMADuuivz9sMPP5wTTjiBmTNncv755zNt2jS++tWvYmbceeedHH744ezevZsvfvGLLFq0iH79+lV6nPnz5zNt2jQWLlzIrl27GDRoEIMHDwbgoosu4uqrrwbg3/7t33jggQf49re/zXnnnce5557LyJEj9zvWjh07GDNmDM8//zy9evXi8ssv55577uH6668HoGPHjixYsIC7776bCRMmcP/992c8v1wPV60SgYg0CunVQ+nVQo899hiDBg1i4MCBLFmyZL9qnIrmzJnDhRdeSMuWLWnbti3nnXfe3m2LFy/m1FNPpW/fvkyZMoUlS5Zkjeett96ie/fu9OrVC4ArrriC2bNn791+0UUXATB48OC9A9Vl8vLLL3PZZZcBlQ9XPXHiRDZu3EizZs0YMmQIDz30ELfffjtvvPEGbdq0yXrs6lCJQERqJNtf7nE6//zzueGGG1iwYAHbtm1j8ODBvP/++0yYMIG5c+fSvn17xowZk3H46aqMGTOG6dOn079/fyZPnsysWbNqFW9qKOvaDGN9yy23cM455zBjxgyGDh3KM888s3e46qeffpoxY8Zw4403cvnll9cq1thKBGb2oJmtNbPFVew3xMx2mdnIbPuJSLK1bt2aM844gyuvvHJvaWDz5s20atWKww47jI8++oiZM2dmPcZpp53G9OnT2b59O1u2bOHJJ5/cu23Lli0ceeSR7Ny5c+/Q0QBt2rRhy5YtBxzrmGOOYcWKFSxfvhyA3/3ud5x++ukHdW65Hq46zhLBZMIMZBlnVzCzpsDPgWdjjENE8sSoUaO48MIL91YRpYZt7t27N127dmXo0KFZ3z9o0CAuueQS+vfvT6dOnRgyZMjebT/5yU848cQTKSws5MQTT9z743/ppZdy9dVXM3HixL2NxAAtWrTgoYce4itf+Qq7du1iyJAhjBs37qDOKzWXcr9+/WjZsuV+w1W/+OKLNGnShOOOO44RI0Ywbdo0fvGLX1BQUEDr1q3rZAKbWIehNrNi4Cl3Pz7D9uuBncCQaL/HK9svnYahFql/Goa6cWk0w1CbWRfgQuCeauw71szmmdm8devWxR+ciEiC5LLX0F3Aze6+p6od3X2Su5e4e0lhYWE9hCYikhy57DVUAkwzM4COwNlmtsvdp+cwJhHJwN2J/r9KA3Yw1f05SwTu3j312swmE9oIlAREGqAWLVpQXl5Ohw4dlAwaMHenvLycFi1a1Oh9sSUCM5sKDAM6mlkZcBtQAODu98b1uSJS94qKiigrK0NtdA1fixYtKCoqqtF7YksE7l690aDCvmPiikNEaq+goIDu3btXvaM0ShpiQkQk4ZQIREQSTolARCThlAhERBJOiUBEJOGUCEREEk6JQEQk4ZQIREQSTolARCThlAhERBJOiUBEJOGUCEREEk6JQEQk4ZQIREQSTolARCThYksEZvagma01s8UZtp9vZovMbGE0Mf0X4opFREQyi7NEMBkYnmX780B/dx8AXAncH2MsIiKSQWyJwN1nAxuybN/q+2ZZbgXUfMZlERGptZy2EZjZhWa2DHiaUCrItN/YqPponuZMFRGpWzlNBO7+f+7eG7gA+EmW/Sa5e4m7lxQWFtZfgCIiCdAgeg1F1Ug9zKxjrmMREUmanCUCM/u8mVn0ehDQHCjPVTwiIknVLK4Dm9lUYBjQ0czKgNuAAgB3vxe4GLjczHYC24FL0hqPRUSknsSWCNx9VBXbfw78PK7PFxGR6mkQbQQiIpI7SgQiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgIpJwSgQiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgIpJwSgQiIgmnRCAiknBKBCIiCRdbIjCzB81srZktzrB9tJktMrM3zOwVM+sfVywiIpJZnCWCycDwLNvfB053977AT4BJMcYiIiIZxDlV5WwzK86y/ZW0xb8DRXHFIiIimTWUNoKvAzMzbTSzsWY2z8zmrVu3rh7DEhHJfzlPBGZ2BiER3JxpH3ef5O4l7l5SWFhYf8GJiCRAbFVD1WFm/YD7gRHuXp7LWEREkipnJQIz6wb8CbjM3d/OVRwiIkkXW4nAzKYCw4COZlYG3AYUALj7vcCPgA7A3WYGsMvdS+KKR0REKhdnr6FRVWy/Crgqrs8XEZHqyXljsYiI5JYSgYhIwikRiIgknBKBiEjCKRGIiCScEoGISMIpEYiIJJwSgYhIwikRiIgknBKBiEjCKRGIiCScEoGISMJVKxGYWSszaxK97mVm55lZQbyhiYhIfahuiWA20MLMugDPApcRJqcXEZFGrrqJwNx9G3ARcLe7fwU4Lr6wRESkvlQ7EZjZycBo4OloXdMq3vCgma01s8UZtvc2s7+Z2adm9t3qhywiInWpuongeuD7wP+5+xIz6wG8WMV7JgPDs2zfAFwLTKhmDCIiEoNqzVDm7i8BLwFEjcbr3f3aKt4z28yKs2xfC6w1s3OqHa2IiNS56vYa+oOZtTWzVsBiYKmZfS/e0Pb7/LFmNs/M5q1bt66+PlZEJBGqWzXUx903AxcAM4HuhJ5D9cLdJ7l7ibuXFBYW1tfHiogkQnUTQUF038AFwBPuvhPw+MISEZH6Ut1E8FtgBdAKmG1mRwOb4wpKRETqT3UbiycCE9NWlZrZGdneY2ZTgWFARzMrA24DCqLj3WtmRwDzgLbAHjO7nn1VUCIiUk+qlQjM7DDCD/lp0aqXgDuATZne4+6jsh3T3dcARdULU0RE4lLdqqEHgS3AV6PHZuChuIISEZH6U60SAfA5d784bfnHZrYwjoBERKR+VbdEsN3MvpBaMLOhwPZ4QhIRkfpU3RLBOOCRqK0A4GPginhCEhGR+lTdXkOvA/3NrG20vDnq5bMozuBERCR+NZqhzN03p3XvvDGGeEREpJ7VZqpKq7MoREQkZ2qTCDTEhIhIHsjaRmBmW6j8B9+AQ2OJSERE6lXWRODubeorEBERyY3aVA2JiEgeUCIQEUk4JQIRkYRTIhARSTglAhGRhIstEZjZg2a21swWZ9huZjbRzJab2SIzGxRXLCIiklmcJYLJwPAs20cAPaPHWOCeGGMREZEMYksE7j4b2JBll/OBRzz4O9DOzI6MK54QU5xHFxFpnHLZRtAFWJm2XBati8XTT8PRR8PatXF9gohI49QoGovNbKyZzTOzeevWrTuoYxxxBKxcCc88U8fBiYg0crlMBKuArmnLRdG6A7j7JHcvcfeSwsLCg/qwgQOhUyeYOfOg3i4ikrdymQieAC6Peg+dBGxy99VxfViTJjB8eCgR7N4d16eIiDQ+cXYfnQr8DTjGzMrM7OtmNs7MxkW7zADeA5YD9wHfjCuWlBEjYMMGmDs37k8SEWk8qjtncY25+6gqtjtwTVyfX5kvfSmUDGbOhJNOqs9PFhFpuBpFY3Fd6dABTjgB/vznXEciItJwJCoRQKgemjsXDrLzkYhI3klkInCHZ5/NdSQiIg1D4hLBsmWhneBrX4PiYpgyJdcRiYjkVqISwZQpMG4c7NkTlktLYexYJQMRSbZEJYJbb4Vt2/Zft21bWC8iklSJSgQffFCz9SIiSZCoRNCtW83Wi4gkQaISwZ13QsuW+69r2TKsFxFJqkQlgtGjYdKkMBx1ysSJYb2ISFIlKhFA+NFfsQKefDIs9+qV03BERHIucYkgpaQkPGsAOhFJusQmgiOOgKIimDcv15GIiORWYhMBwJAhKhGIiCQ+ESxfDl27hmEnNOSEiCRRbPMRNAabNoXnsrLwnBpyAtSTSESSI9YSgZkNN7O3zGy5md1Syfajzex5M1tkZrPMrCjOeCqq7K9/DTkhIkkT51SVTYHfACOAPsAoM+tTYbcJwCPu3g+4A/iPuOKpzKpVla/XkBMikiRxlghOAJa7+3vu/hkwDTi/wj59gBei1y9Wsj1WmYaW6NChPqMQEcmtOBNBF2Bl2nJZtC7d68BF0esLgTZmdsDPsJmNNbN5ZjZvXR1OLXbnnVBQcOD6Jk1g1646+xgRkQYt172GvgucbmavAacDq4DdFXdy90nuXuLuJYWFhXX24aNHwy1pLRetW0ObNrB2bbjPoKoeRO5wzjlhjgMRkcYqzl5Dq4CuactF0bq93P1DohKBmbUGLnb3jTHGdIAf/xgGDYI1a+A739k3X0F5OVx9dXidqQfRrFkwYwaYwXXXwbHH1kvIIiJ1Ks4SwVygp5l1N7NDgEuBJ9J3MLOOZpaK4fvAgzHGUykzuOAC+NnPDpy0Zvv27D2I/v3foVOnMILpT38ab5wiInGJLRG4+y7gW8AzwJvAY+6+xMzuMLPzot2GAW+Z2dtAZyBnA0Jn6ilUWlr5jWavvgrPPQff/S5ccw1MmxbmQxYRaWzM3XMdQ42UlJT4vBgGCCouDj/6mbRsGYawTlUTXXhhqBr64APYsSO8/8IL4fe/r/PQRERqzczmu3tJZdty3VjcYFQ2aU26bdvga18LXU5//nOYPh2uvTY0LhcWwje/CVOnwttv11/MIiJ1QSWCNFOmhDaBbCUDCO0KhxwSbkhL3XPw0UfQvTuccQb86U/QvHksIYqIHBSVCKopNWlN+gxmlXGHQw/d/8azzp1Dg/OMGfClL8H69bGGKiJSZ5QIKlFVNRHAxo0HNiJfe22oHnr1VTjpJHjzzezH2LoV3n+/1uGKiNSKEkElKpvbuDKlpXDZZaGqKJUULr0UXnwRNm+Gfv3CsRYs2PeeHTtg9mz4138NN6316AHXXw+ffhrrKYmIZKQ2gipMmRKGpq54j0Fl0nsWrVoFv/wl3H8/bNkS5jzYuDG8htDIfMkl0KwZ3HsvDBwIjz4KPXvGez4ikkzZ2giUCKqhuo3IKUcfHaqXRo8Ocx488EAoFRQWhsfnPgfnngutWoX9n3gilBB27ICvfz2UEHr0CMvPPw9//zucfTacfHJ85ygi+U2JoI5Uda9BOrPQqJyeFLIpKwvJZupU2L0bTjkFFi4M7QgpJ54I48fDhg3wyishuQweHJLIP/0TNG160KcmInlOvYbqSHUakVNS+bWydoTKFBXBww+HXks33RRKEqNHw8yZYdyjX/0qPI8ZAzfeCPPnhzaIF14IpYVu3eBb34Knn65eNZaISIpKBDWUXk2U+qu/JmpaUki3ezfMmxd+9I88Mqz77DN46il45BH4y19CEmjePLQ5HH889O0bhtr+8MPwaN0aSkrCfM0tW8Ibb8DixWFcpQEDwgB8XbuGOEUkf6hqKCY1bTuoqDZJoTI7dsCcOfDMM6Ha6I039t3P0KRJuNdh06bKSwzpSa1zZzjrrFDddNJJ4eY5CPdOdO5cuxhFJDeUCGJWk55FmdR1UoBwvLVrw3NhYWhD2LUr3N8wd27ostq3byg5HHJISBwLFsDLL4fSRWVzAHXrBqeeGkoO27aFRLMxGji8WTNo0QJGjIAvfzksi0jDoERQD2pbZZQujqRQU3v2wKJF8Prr+87l449DI/WcOWFIDQjdYNu3D6937Qr3T2zdGqquLr88NHAXF4fhN9q1q//zEJFAiaCe1WVSKCiAtm1DT6HDDw/rNmwIf5nnKkm4hxjatNlXbZTy2WdhmI0HHwzPu9PmmysshN694Zhjwnlt3hwe7dtDr15h/bHHhteVTSEqIgdPiSCH6jIpVJQ6XmrMo1wniIo2bYJ33w3DaLz/fhiZddkyeOutEHfbtqHxurw8dJ9NOeSQkDA6dQrVT9u2hXXduoVSUlFRKHEccURo2O7eXY3bIlXJWSIws+HA/wBNgfvd/WcVtncDHgbaRfvc4u4zsh2zsSWCdHEmhXQNPUFUZutWeOcdWLo0tFW88UaoimrZMjy2b4eVK8N3t2PH/u897LDQZnHssaEdZM+e0HOqb9+wvk+fUDLZsiWUWI48UolDkicnicDMmgJvA18CyghTV45y96Vp+0wCXnP3e8ysDzDD3YuzHbcxJ4J09ZUU0jXGBFFRqlrqo4/CPNPvvhvuqZg/H5YvD+doFhLH9u3hPRW/3/794aqrwjm3aRNKJOXlobSRuttbJN/kKhGcDNzu7l+Olr8P4O7/kbbPb4H33P3n0f6/dPdTsh03XxJBulwkhXSVJYiG0h5xsHbvDiWM+fNDdVSLFqEq6rPP4A9/CL2jUqWH1PfdtGm4l+Lkk0P1U6tWoTTy+c+HkkXr1rk9J5HayFUiGAkMd/erouXLgBPd/Vtp+xwJPAu0B1oBZ7n7/EqONRYYC9CtW7fBpQfbcb8RSCWFDz4IP8ap6oxcy4fSRLoFC+CPfwyN0p06hR5NS5eGXlH/+MeBXYGbNAlVTJ/7XNi3XbvwXXTqFO6tOOII6NIlPKuhWxqihkjEqpAAAAy1SURBVJwIboxi+GVUIngAON7d92Q6bj6WCLKpmBggVGPkouRQmUy9mhpzicI9VCt98klou3jzzTDHxKuvhkbtTZtC+0VqJNl0ZqHNomnTcB9Fq1YhefTsGR59+sBxx8FRR6mdQupXQ64aWkJIFiuj5feAk9x9babjJi0RZNLQE0RF+VaigFBSW7cutFesXh2GHl+1KiSJ3bvDY9Om0HbxzjvhdUrbtvuSQ8+eoedTcXH4Tpo3DyWQggLo2FEJQ+pGrhJBM0Jj8ReBVYTG4n9x9yVp+8wEHnX3yWZ2LPA80MWzBKVEkF0+JIjGXJrIxD0kjaVLYcmSUMp4552QJFasCG0VlenaFc48Mzy6dNnXbrFhQ0g6q1eHXlAnnBDaMpQ0JJNcdh89G7iL0DX0QXe/08zuAOa5+xNRT6H7gNaAAze5+7PZjqlEcHAaW4JIl+/JYufO0DX2/ffD865dITF88gn89a9hxrsNG6o+Trt2oRrq8MPDd9WjRxhgsKQk3My3dm14NGsWuto2bx7/uUnDoRvKJKPKEkT6D62SRe7t2RNKEOXlITls2xbuxj7qqNA4vXLl/m0Yqe6wK1aEpFKZpk3DTXuDBsHpp8OwYSFxqESRv5QIpFayJYuG0qupOhricB1x2r49jBc1d24YyqNTp/DYvj3csPf66yF5rI1a5Dp12tdW0bVr+I7atQuN3xASbUFBmAejV6/QjiGNhxKBxEYlisbNPdxn8dJLIWGUloZHWdmBd3CnO+ywUOXUs2f4brp1C+tSd4J36RIeShYNhxKB5FRjbp9Il7RksWNH6AG1eXNYTt2xvWBBuNdi/vzQrlFeXvn7mzcPJYwuXULvp8LC8Do1ZlTXrqGhW/dd1A8lAmmQ8qU0kS5pyQLCvRYrV4bnbdtCO8bKlaFH1LvvhqFA1q8PVVDpXWghfF+dO4ekcPTR4ZEatjz1OPTQuo13zZpQDZa00ooSgTRaSUkW3bqFuadnzAjnmo8JA0Ky+OCDfdVPq1aF55UrQ+P2Bx8cWCV11FGhN1S3bmFsqNQcGN27hwbu4uLw76GqiZDefht++EN47LHwXU+Zkqw5MpQIJK9VlSwaY8M2JLN04R5u0EsNXf7ee6FUsXx5SBhbt4ZHZe0XqQSRuteiZcvwQ9++fZiN7/HHw5hTF10EU6eGJDJ9euhKmwRKBCLkT1tFuiQmCwjVT6lEUVoazvXjj8O0qak5LLZuDcsffxyWR40K179z5zDL3siRoc1j5MhQNVVUFKqmunffd4d3PlEiEMkiH6uf0iU1WVRl5UoYNw4WLgx3aKdfX7PQjpCaACn1nHocdVRY17FjKHk0hgZvJQKRWlKyyO9ksXNnSAalpfuqpVatCg3Lq1eH5zVrMt+glxpgsHXr8OjcGU45BU49Ndy0t2dPqM7asyf0nmrbtv5v3lMiEKkHSUkWRx+9f8N2UhLGnj3hHNesgQ8/DAli/fp9kyCl2i+2bAnfy/z5mRPHoYeGqqgBA2DIEBg8OLRltGgRShhFReHu77qkRCDSQGRKFum9hnI1QVFdSXrpIuWTT8L9FkuXhjm3W7QI69eu3Vf6mD8/9JaqqFWrUJIoKQnfV2r8qN69Qw+qg6FEINLIJKV0kfRkAWFU2tdf39cbauvWfUODvPZa6PGUcvPN8LOfZT5WNkoEInlIySL/k8WePeEmvA0bwvUsLAy9mg6GEoFIQiUxWSTl5ryaUiIQkYzyPVmASheQPREkbLQNEalo9Oh9s6StXx8e6a/d4Xe/C72FzMLz+PH7ljt02PcD21DnM0glsdRcDe77vy4thcsuC/F37BgeTZrs/7q4OCTNfBT3DGXDgf8hzFB2v7v/rML2/wbOiBZbAp3cPevoHyoRiDRc+V66aMwli1zNWdyUMGfxl4AywpzFo9x9aYb9vw0MdPcrsx1XiUCkcVOyyE2yyFXV0AnAcnd/z90/A6YB52fZfxQwNcZ4RKQBqGlVVKrqKR+roYqL4ZvfDM+5rIqKMxF0AVamLZdF6w5gZkcD3YEXMmwfa2bzzGzeunXr6jxQEWlYapMs0tswoGEmjFSyKC2Fe+4Jz9Vtt4gjQVQxgne9uRR43N13V7bR3ScBkyBUDdVnYCLSMI0eXb3qlcZcFZVeukgpLYWxY8PruqpeirNEsAromrZcFK2rzKWoWkhEYpCPVVHbtoXkVlfiTARzgZ5m1t3MDiH82D9RcScz6w20B/4WYywiIhk1xmTxwQd1d6zYEoG77wK+BTwDvAk85u5LzOwOMzsvbddLgWne2O5sE5FEaWjJolu3ujkO6M5iEZF6ld5mUXE4jOq2W7RsCZMm1ayNIFv30YbSWCwikgi1beSO4z4EJQIRkQaougmjLmisIRGRhFMiEBFJOCUCEZGEUyIQEUk4JQIRkYRrdPcRmNk6oLQGb+kIrI8pnIYsieedxHOGZJ53Es8ZanfeR7t7YWUbGl0iqCkzm5fpJop8lsTzTuI5QzLPO4nnDPGdt6qGREQSTolARCThkpAIJuU6gBxJ4nkn8ZwhmeedxHOGmM4779sIREQkuySUCEREJAslAhGRhMvrRGBmw83sLTNbbma35DqeOJhZVzN70cyWmtkSM7suWn+4mf3FzN6JntvnOtY4mFlTM3vNzJ6Klrub2T+ia/5oNDte3jCzdmb2uJktM7M3zezkJFxrM7sh+ve92MymmlmLfLvWZvagma01s8Vp6yq9thZMjM59kZkNqs1n520iMLOmwG+AEUAfYJSZ9cltVLHYBXzH3fsAJwHXROd5C/C8u/cEno+W89F1hBnwUn4O/Le7fx74GPh6TqKKz/8Af3b33kB/wrnn9bU2sy7AtUCJux8PNCXMbJhv13oyMLzCukzXdgTQM3qMBe6pzQfnbSIATgCWu/t77v4ZMA04P8cx1Tl3X+3uC6LXWwg/DF0I5/pwtNvDwAW5iTA+ZlYEnAPcHy0bcCbweLRLXp23mR0GnAY8AODun7n7RhJwrQlzpxxqZs2AlsBq8uxau/tsYEOF1Zmu7fnAIx78HWhnZkce7GfncyLoAqxMWy6L1uUtMysGBgL/ADq7++po0xqgc47CitNdwE3Anmi5A7Axmi8b8u+adwfWAQ9F1WH3m1kr8vxau/sqYALwASEBbALmk9/XOiXTta3T37d8TgSJYmatgT8C17v75vRtHvoI51U/YTM7F1jr7vNzHUs9agYMAu5x94HAJ1SoBsrTa92e8Bdwd+AooBUHVqHkvTivbT4nglVA17Tlomhd3jGzAkISmOLuf4pWf5QqKkbPa3MVX0yGAueZ2QpCtd+ZhPrzdlH1AeTfNS8Dytz9H9Hy44TEkO/X+izgfXdf5+47gT8Rrn8+X+uUTNe2Tn/f8jkRzAV6Rj0LDiE0Lj2R45jqXFQv/gDwprv/V9qmJ4ArotdXAP+vvmOLk7t/392L3L2YcG1fcPfRwIvAyGi3vDpvd18DrDSzY6JVXwSWkufXmlAldJKZtYz+vafOO2+vdZpM1/YJ4PKo99BJwKa0KqSac/e8fQBnA28D7wK35jqemM7xC4Ti4iJgYfQ4m1Bf/jzwDvAccHiuY43xOxgGPBW97gG8CiwH/hdonuv46vhcBwDzous9HWifhGsN/BhYBiwGfgc0z7drDUwltIHsJJT+vp7p2gJG6BX5LvAGoUfVQX+2hpgQEUm4fK4aEhGRalAiEBFJOCUCEZGEUyIQEUk4JQIRkYRTIhCJmNluM1uY9qizwdvMrDh9VEmRhqRZ1buIJMZ2dx+Q6yBE6ptKBCJVMLMVZvafZvaGmb1qZp+P1heb2QvRePDPm1m3aH1nM/s/M3s9epwSHaqpmd0Xjav/rJkdGu1/bTSfxCIzm5aj05QEUyIQ2efQClVDl6Rt2+TufYFfE0Y9BfgV8LC79wOmABOj9ROBl9y9P2EsoCXR+p7Ab9z9OGAjcHG0/hZgYHSccXGdnEgmurNYJGJmW929dSXrVwBnuvt70QB/a9y9g5mtB450953R+tXu3tHM1gFF7v5p2jGKgb94mGAEM7sZKHD3n5rZn4GthCEjprv71phPVWQ/KhGIVI9neF0Tn6a93s2+NrpzCOPGDALmpo2oKVIvlAhEqueStOe/Ra9fIYx8CjAamBO9fh4YD3vnVD4s00HNrAnQ1d1fBG4GDgMOKJWIxEl/eYjsc6iZLUxb/rO7p7qQtjezRYS/6kdF675NmC3se4SZw/41Wn8dMMnMvk74y388YVTJyjQFfh8lCwMmeph+UqTeqI1ApApRG0GJu6/PdSwicVDVkIhIwqlEICKScCoRiIgknBKBiEjCKRGIiCScEoGISMIpEYiIJNz/Bz+MuDKzY2aMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rmiRDvMYQb3",
        "colab_type": "code",
        "outputId": "e0efa2d5-d27a-4ff7-9b34-4fe627f9f9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.clf() # clear figure\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-W5TpwBYSSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}